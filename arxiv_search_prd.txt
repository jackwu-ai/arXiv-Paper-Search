<context>
# Overview
This document outlines the requirements for a simple web application, "arXiv Explorer," designed to help users search for and discover research papers hosted on arXiv. The primary goal is to provide a clean, fast, and straightforward interface for researchers, students, and enthusiasts to find relevant academic papers using a Python-based backend.

# Core Features
1.  **Keyword Search Interface:**
    -   **What it does:** Allows users to input search terms (keywords, author names, titles).
    -   **Why it's important:** This is the primary mechanism for users to find papers.
    -   **How it works:** A simple HTML form will submit the search query to the backend. The backend will then query the arXiv API.

2.  **arXiv API Integration (Search):**
    -   **What it does:** The backend will programmatically interact with the official arXiv API to perform searches based on user queries.
    -   **Why it's important:** Provides access to arXiv's vast database of research papers.
    -   **How it works:** The Python backend will use a library (e.g., `arxiv`) or make direct HTTP requests to the arXiv API endpoint (e.g., `http://export.arxiv.org/api/query`). It will parse the XML response.

3.  **Results Display:**
    -   **What it does:** Presents the search results to the user in a clear and readable format.
    -   **Why it's important:** Allows users to easily scan and identify relevant papers.
    -   **How it works:** The backend will pass the processed search results to a frontend template. Each result should display key information such as title, authors, publication date, summary/abstract, and a direct link to the PDF on arXiv.

# User Experience
-   **User Personas:**
    -   Students looking for papers for their research or coursework.
    -   Researchers staying updated on new publications in their field.
    -   Enthusiasts exploring scientific topics.
-   **Key User Flows:**
    1.  User lands on the homepage with a prominent search bar.
    2.  User types a query and presses "Search" or hits Enter.
    3.  The page displays a list of relevant papers, or a "no results found" message.
    4.  User can click on a paper's title or link to view it on the arXiv website.
-   **UI/UX Considerations:**
    -   Minimalist design focusing on the search functionality.
    -   Clear visual hierarchy for search results.
    -   Responsive design for usability on different screen sizes (desktop focus for MVP).
    -   Fast load times for search results.
</context>
<PRD>
# Technical Architecture
-   **System Components:**
    -   **Frontend:** Simple HTML, CSS, and potentially minimal JavaScript for user interaction. No complex SPA framework needed for MVP.
    -   **Backend:** Python (Flask or FastAPI recommended for simplicity).
    -   **arXiv API:** External dependency for search functionality.
-   **Data Models:**
    -   **Search Query:** User-provided string.
    -   **Paper Result:** (Derived from arXiv API)
        -   ID (arXiv ID)
        -   Title
        -   Authors (list of strings)
        -   Summary (abstract)
        -   Published Date
        -   PDF Link
        -   Categories (optional)
-   **APIs and Integrations:**
    -   **arXiv API:** Primary integration. Documentation at `https://arxiv.org/help/api/user-manual`. Key parameters: `search_query`, `start`, `max_results`.
-   **Infrastructure Requirements:**
    -   Standard web hosting environment capable of running a Python web application.
    -   No database required for MVP.

# Development Roadmap
-   **MVP Requirements:**
    1.  Basic frontend with a search input field and a results display area.
    2.  Python backend endpoint that accepts a search query.
    3.  Backend logic to call the arXiv API with the user's query.
    4.  Backend logic to parse the XML response from arXiv.
    5.  Backend logic to extract title, authors, summary, publication date, and PDF link for each paper.
    6.  Display of up to 10 search results on the frontend.
    7.  Direct links to the arXiv PDF for each result.
-   **Future Enhancements (Post-MVP):**
    -   Pagination for search results.
    -   Advanced search filters (e.g., by date range, author, category).
    -   Sorting options for results (e.g., by relevance, date).
    -   User accounts to save searches or bookmark papers (would require a database).
    -   Display of arXiv categories for each paper.
    -   More robust error handling and user feedback.
    -   **AI-Powered Summarization:**
        -   A button displayed next to the search results (or per result).
        -   When clicked, it takes the first 5 search results (or a specific paper).
        -   It sends the abstracts/summaries of these papers to a ChatGPT API (or similar LLM).
        -   The LLM generates a concise summary of the key takeaways from these papers.
        -   The summarized takeaways are then presented to the user, potentially in a modal or a dedicated section on the page.
    -   **Email Newsletter Feature:**
        -   **What it does:** Allows users to subscribe to a weekly newsletter containing summaries of selected papers and links to the papers.
        -   **Why it's important:** Provides users with a convenient way to stay updated on research relevant to their interests without actively visiting the site.
        -   **How it works:**
            -   **Frontend:**
                -   An input field for users to enter their email address.
                -   A "Subscribe" button to opt-in to the newsletter.
                -   A "Test Send" button (perhaps admin-only or for subscribed users) to trigger an immediate test email to their address.
            -   **Backend:**
                -   Store subscribed email addresses (requires a simple database or persistent storage solution).
                -   A scheduled task (e.g., weekly cron job or scheduled function) to:
                    -   Potentially gather "top" or "newly summarized" papers (criteria to be defined).
                    -   Format an email with these summaries and links.
                    -   Use the Gmail API (or another email service API) to send the newsletter to all subscribed users.
                -   An endpoint to handle the "Test Send" functionality.
            -   **Authentication & Security:**
                -   Consider email verification (double opt-in) for subscriptions.
                -   Securely manage API keys for the Gmail API.
                -   Implement unsubscription mechanism.

# Logical Dependency Chain
1.  **Backend - arXiv API Wrapper:** Implement a Python function/module to query the arXiv API and parse its XML response. This should be testable independently.
2.  **Backend - Search Endpoint:** Create a simple Python web server (Flask/FastAPI) with an endpoint that takes a search string, uses the API wrapper, and prepares data for the frontend.
3.  **Frontend - Basic Search Form & Results Structure:** Create the HTML structure for the search input and an area to display results.
4.  **Integration - Display Results:** Connect the frontend to the backend endpoint to display actual search results. Ensure basic styling for readability.

# Risks and Mitigations
-   **arXiv API Rate Limiting/Changes:**
    -   **Risk:** The arXiv API might have rate limits or undergo changes that break the integration.
    -   **Mitigation:** Adhere to API usage guidelines. Implement basic error handling for API request failures. Keep the arXiv API client library (if used) updated.
-   **Complexity of XML Parsing:**
    -   **Risk:** Parsing the arXiv XML response might be more complex than anticipated.
    -   **Mitigation:** Use a well-tested Python XML parsing library (e.g., `xml.etree.ElementTree` or `lxml`). Start with parsing only the essential fields for MVP.
-   **Keeping it Simple:**
    -   **Risk:** Scope creep, adding too many features to the MVP.
    -   **Mitigation:** Strictly adhere to the MVP requirements. Defer all non-essential features to "Future Enhancements."

# Appendix
-   **arXiv API Documentation:** `https://arxiv.org/help/api/user-manual`
-   **arXiv Python Library (Optional):** `https://github.com/lukasschwab/arxiv.py` (can simplify API interaction)
</PRD> 